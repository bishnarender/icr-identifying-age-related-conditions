{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91c313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f557aa42-ed5f-47a7-bcd5-6650379fccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/lib/cuda/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8c6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 21:46:43.279248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-05 21:46:43.839608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ProgbarLogger\n",
    "from tensorflow.keras import regularizers as R\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import optimizers as O\n",
    "from tensorflow.keras import constraints as C\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, sparse_categorical_crossentropy, Loss\n",
    "tf.keras.utils.set_random_seed(722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f13d7f-4dba-4e0c-93ae-dd3f358280b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf60ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss_np(y_true, y_pred):\n",
    "    # y_true.shape, y_pred.shape => (62,), (62,)\n",
    "    # np.unique(y_true) => [0 1]\n",
    "\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    # .bincount(x, ...) => count number of occurrences of each value in array of non-negative ints.\n",
    "    nc = np.bincount(y_true)\n",
    "    # nc => [51 11]   i.e., count of 0, count of 1, count of 2 and so on.\n",
    "    \n",
    "    \n",
    "    # np.log(1-y_pred) => logarithm of the probability of a sample belonging to class \"0\".\n",
    "    # np.sum( np.where(y_true==0,1,0) * np.log(1-y_pred) ) => log loss contribution by samples belonging to class \"0\".\n",
    "    # -1/nc[0]*( log loss contribution by samples belonging to class \"0\" ) => scale by the inverse of the count of class \"0\" instances in the dataset.\n",
    "    balanced_log_loss_score = (\n",
    "                                -1/nc[0]*(np.sum( np.where(y_true==0,1,0) * np.log(1-y_pred) )) \n",
    "                               - 1/nc[1]*(np.sum( np.where(y_true!=0,1,0) * np.log(y_pred) ))\n",
    "                              ) / 2\n",
    "    return balanced_log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476fc39-5e45-4af2-a68e-01292a9725bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ae389-8db0-4ab6-9561-76f7743c8e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638eb913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    AB          AF         AH         AM        AR        AX  \\\n",
      "Id                                                                             \n",
      "000ff2bfdfe9  0.209377  3109.03329  85.200147  22.394407  8.138688  0.699861   \n",
      "007255e47698  0.145282   978.76416  85.200147  36.968889  8.138688  3.632190   \n",
      "013f2bd269f5  0.470030  2635.10654  85.200147  32.360553  8.138688  6.732840   \n",
      "\n",
      "                    AY         AZ        BC         BD   ...        FL  \\\n",
      "Id                                                       ...             \n",
      "000ff2bfdfe9  0.025578   9.812214  5.555634  4126.58731  ...  7.298162   \n",
      "007255e47698  0.025578  13.517790  1.229900  5496.92824  ...  0.173229   \n",
      "013f2bd269f5  0.025578  12.824570  1.229900  5135.78024  ...  7.709560   \n",
      "\n",
      "                   FR        FS         GB         GE            GF  \\\n",
      "Id                                                                    \n",
      "000ff2bfdfe9  1.73855  0.094822  11.339138  72.611063   2003.810319   \n",
      "007255e47698  0.49706  0.568932   9.292698  72.611063  27981.562750   \n",
      "013f2bd269f5  0.97556  1.198821  37.077772  88.609437  13676.957810   \n",
      "\n",
      "                     GH         GI         GL  Class  \n",
      "Id                                                    \n",
      "000ff2bfdfe9  22.136229  69.834944   0.120343      1  \n",
      "007255e47698  29.135430  32.131996  21.978000      0  \n",
      "013f2bd269f5  28.022851  35.192676   0.196941      0  \n",
      "\n",
      "[3 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv', index_col='Id')\n",
    "print(train_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d14be88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "000ff2bfdfe9    B\n",
       "007255e47698    A\n",
       "013f2bd269f5    B\n",
       "Name: EJ, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['EJ'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5cb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807a8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.isna().any() =>\n",
    "# ...\n",
    "# BQ        True\n",
    "# BR       False\n",
    "# BZ       False\n",
    "# CB        True\n",
    "# CC        True\n",
    "# CD       False\n",
    "# ...\n",
    "# Class    False\n",
    "# dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13ae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e19bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_fill = train_df.isna().any()\n",
    "nan_fill *= train_df.min() - train_df.max()\n",
    "# nan_fill =>\n",
    "# ...\n",
    "# BP         -0.000000\n",
    "# BQ       -343.312950\n",
    "# BR         -0.000000\n",
    "# BZ         -0.000000\n",
    "# CB      -2258.936407\n",
    "# CC         -3.926157\n",
    "# CD         -0.000000\n",
    "# ...\n",
    "# Class      -0.000000\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6d90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_df.columns)==len(train_df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1f52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_fill[nan_fill == 0] = train_df.median()\n",
    "train_df = train_df.fillna(nan_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9900641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,:-1].values\n",
    "tgt = train_df.Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c773fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0417a8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15df3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the hard-coded label from baseline DNN model, where \"1\" is difficult to predict, \"0\" - easy.\n",
    "### (y_true = 1 and y_pred < 0.2) or (y_true = 0 and y_pred > 0.8) -> label \"1\", otherwise label \"0\".\n",
    "tgt2 = np.asarray([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
    "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea808e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tgt) == len(tgt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d3ccc6-bc3d-4fab-96a9-d1a3166fbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 # 32 # 8 my_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5b11f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.keras.utils.register_keras_serializable() => registers an object with the Keras serialization framework.\n",
    "#        This allows you to use custom layer/class/function in your Keras models and ensure that it can be -\n",
    "#        - serialized and deserialized correctly when saving and loading models.\n",
    "#        This decorator injects the decorated class or function into the Keras custom object dictionary, so that -\n",
    "#        - it can be serialized and deserialized without needing an entry in the user-provided custom object dict.\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def smish(x):\n",
    "    # smish(x)=x⋅tanh(ln(1+σ(x)))\n",
    "    return x * K.tanh(K.log(1 + K.sigmoid(x)))\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class GatedLinearUnit(Model): # L.Layer # Model my_\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear = L.Dense(units)\n",
    "        self.sigmoid = L.Dense(units, activation=\"sigmoid\")\n",
    "        self.units = units\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "\n",
    "    def model(self):\n",
    "        # input_shape=(not include batch size).\n",
    "        x = tf.keras.Input(shape=(self.units), batch_size=batch_size)\n",
    "        return tf.keras.Model(inputs=x, outputs=self.call(x)) \n",
    "    \n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class GatedResidualNetwork(Model): # L.Layer # Model my_\n",
    "    def __init__(self, units, dropout_rate, num_features, concat, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.relu_dense = L.Dense(units, activation=smish)\n",
    "        self.linear_dense = L.Dense(units)\n",
    "        self.dropout = L.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = L.LayerNormalization()\n",
    "        self.project = L.Dense(units)\n",
    "        self.num_features = num_features\n",
    "        self.concat = concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        config['dropout_rate'] = self.dropout_rate\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.relu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "    def model(self):\n",
    "        # input_shape=(not include batch size).\n",
    "        if (self.concat and 2*self.units-self.num_features): sh = self.num_features*(2*self.units-self.num_features)\n",
    "        elif (self.concat and 2*self.units-self.num_features==0):  sh = self.num_features\n",
    "        elif (self.concat==False and 2*self.units-self.num_features): sh = 2*self.units-self.num_features\n",
    "        else: sh = 1        \n",
    "        x = tf.keras.Input(shape=(sh), batch_size=batch_size)\n",
    "        return tf.keras.Model(inputs=x, outputs=self.call(x)) \n",
    "    \n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class VariableSelection(Model): # L.Layer # Model my_\n",
    "    def __init__(self, num_features, units, dropout_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate, num_features, True)\n",
    "\n",
    "        self.grns = list()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate, num_features, False)\n",
    "            self.grns.append(grn)\n",
    "            \n",
    "        self.softmax = L.Dense(units=num_features, activation=\"softmax\")\n",
    "        self.num_features = num_features\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['num_features'] = self.num_features\n",
    "        config['units'] = self.units\n",
    "        config['dropout_rate'] = self.dropout_rate\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        v = L.concatenate(inputs)\n",
    "        v = self.grn_concat(v)\n",
    "        v = tf.expand_dims(self.softmax(v), axis=-1)\n",
    "\n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = tf.stack(x, axis=1)\n",
    "\n",
    "        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n",
    "        return outputs\n",
    "        \n",
    "    def model(self):\n",
    "        sh = [2*self.units-self.num_features if 2*self.units-self.num_features else 1][0]\n",
    "        x = []\n",
    "        for idx in range(self.num_features):\n",
    "            x.append(tf.keras.layers.Input(shape=(sh)))\n",
    "        return tf.keras.Model(inputs=x, outputs=self.call(x))     \n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class VariableSelectionFlow(Model): # L.Layer # Model my_\n",
    "    def __init__(self, num_features, units, dropout_rate, dense_units=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n",
    "        self.split = L.Lambda(lambda t: tf.split(t, num_features, axis=-1))\n",
    "        self.dense = dense_units\n",
    "        if dense_units:\n",
    "            self.dense_list = [L.Dense(dense_units, \\\n",
    "                                       activation='linear') \\\n",
    "                               for _ in tf.range(num_features)\n",
    "                              ]\n",
    "        self.num_features = num_features\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_units = dense_units\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['num_features'] = self.num_features\n",
    "        config['units'] = self.units\n",
    "        config['dropout_rate'] = self.dropout_rate\n",
    "        config['dense_units'] = self.dense_units\n",
    "        return config        \n",
    "    \n",
    "    def call(self, inputs):   \n",
    "        split_input = self.split(inputs)\n",
    "        if self.dense:\n",
    "            l = [self.dense_list[i](split_input[i]) for i in range(len(self.dense_list))]\n",
    "        else:\n",
    "            l = split_input\n",
    "        return self.variableselection(l)           \n",
    "\n",
    "    def model(self):\n",
    "        # input_shape=(not include batch size).\n",
    "        sh = 2*self.units-[self.dense_units if self.dense_units else 0][0]\n",
    "        x = tf.keras.Input(shape=(sh), batch_size=batch_size)\n",
    "        return tf.keras.Model(inputs=x, outputs=self.call(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee6e47-1c5a-4cc6-bf78-70bd0f3b3ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ad03e3-4c4d-49f6-925c-278d46ea42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(VariableSelectionFlow(units_2, units_3, drop_2).model(), to_file=\"model.png\", expand_nested=True, show_shapes=True)\n",
    "#tf.keras.utils.plot_model(VariableSelection(units_2, units_3, drop_2).model(), to_file=\"model.png\", expand_nested=True, show_shapes=True)\n",
    "#tf.keras.utils.plot_model(GatedResidualNetwork(units_3, drop_2, units_2, True).model(), to_file=\"model.png\", expand_nested=True, show_shapes=True)\n",
    "#tf.keras.utils.plot_model(GatedResidualNetwork(units_3, drop_2, units_2, False).model(), to_file=\"model.png\", expand_nested=True, show_shapes=True)\n",
    "#tf.keras.utils.plot_model(GatedLinearUnit(units_3).model(), to_file=\"model.png\", expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc56d2-cd8d-4952-b660-6a68ba9c829d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61e3f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 5______, ________repeat 1__________\n",
      "Epoch 1/250\n",
      "70/70 [==============================] - 216s 226ms/step - loss: 0.4707 - val_loss: 0.4658 - lr: 0.0012\n",
      "Epoch 2/250\n",
      "70/70 [==============================] - 10s 141ms/step - loss: 0.4226 - val_loss: 0.4502 - lr: 0.0012\n",
      "Epoch 3/250\n",
      "70/70 [==============================] - 10s 140ms/step - loss: 0.3771 - val_loss: 0.4217 - lr: 0.0012\n",
      "Epoch 4/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3203\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0012327659666771069.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.3203 - val_loss: 0.4670 - lr: 0.0012\n",
      "Epoch 5/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3533\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0012315331982681527.\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.3533 - val_loss: 0.4564 - lr: 0.0012\n",
      "Epoch 6/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3063\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0012303017091471703.\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.3063 - val_loss: 0.4230 - lr: 0.0012\n",
      "Epoch 7/250\n",
      "70/70 [==============================] - 10s 141ms/step - loss: 0.2577 - val_loss: 0.3873 - lr: 0.0012\n",
      "Epoch 8/250\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.2621 - val_loss: 0.3715 - lr: 0.0012\n",
      "Epoch 9/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2496\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0012290713830152527.\n",
      "70/70 [==============================] - 9s 133ms/step - loss: 0.2496 - val_loss: 0.3995 - lr: 0.0012\n",
      "Epoch 10/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2251\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0012278423361713068.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.2251 - val_loss: 0.4103 - lr: 0.0012\n",
      "Epoch 11/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2240\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0012266144523164256.\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.2240 - val_loss: 0.3859 - lr: 0.0012\n",
      "Epoch 12/250\n",
      "70/70 [==============================] - 10s 139ms/step - loss: 0.1939 - val_loss: 0.3393 - lr: 0.0012\n",
      "Epoch 13/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2028\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0012253878477495163.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.2028 - val_loss: 0.4222 - lr: 0.0012\n",
      "Epoch 14/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.001224162406171672.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.1806 - val_loss: 0.3726 - lr: 0.0012\n",
      "Epoch 15/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0012229382438817993.\n",
      "70/70 [==============================] - 10s 139ms/step - loss: 0.1642 - val_loss: 0.3817 - lr: 0.0012\n",
      "Epoch 16/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.001221715360879898.\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.1794 - val_loss: 0.3753 - lr: 0.0012\n",
      "Epoch 17/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.001220493640867062.\n",
      "70/70 [==============================] - 9s 133ms/step - loss: 0.1576 - val_loss: 0.3496 - lr: 0.0012\n",
      "Epoch 18/250\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.1497 - val_loss: 0.3121 - lr: 0.0012\n",
      "Epoch 19/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1187\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012192732001421974.\n",
      "70/70 [==============================] - 9s 132ms/step - loss: 0.1187 - val_loss: 0.4316 - lr: 0.0012\n",
      "Epoch 20/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1274\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012180539224063978.\n",
      "70/70 [==============================] - 9s 132ms/step - loss: 0.1274 - val_loss: 0.3154 - lr: 0.0012\n",
      "Epoch 21/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0012168359239585697.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.1350 - val_loss: 0.3715 - lr: 0.0012\n",
      "Epoch 22/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1235\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.001215619088499807.\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.1235 - val_loss: 0.4644 - lr: 0.0012\n",
      "Epoch 23/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1486\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.001214403416030109.\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.1486 - val_loss: 0.3649 - lr: 0.0012\n",
      "Epoch 24/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012131890228483826.\n",
      "70/70 [==============================] - 9s 133ms/step - loss: 0.1356 - val_loss: 0.3489 - lr: 0.0012\n",
      "Epoch 25/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1058\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0012119757926557213.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.1058 - val_loss: 0.3976 - lr: 0.0012\n",
      "Epoch 26/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0928\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012107638417510316.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.0928 - val_loss: 0.3992 - lr: 0.0012\n",
      "Epoch 27/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0915\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.001209553053835407.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.0915 - val_loss: 0.4109 - lr: 0.0012\n",
      "Epoch 28/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0853\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0012083435452077537.\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.0853 - val_loss: 0.3749 - lr: 0.0012\n",
      "Epoch 29/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0783\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0012071351995691657.\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.0783 - val_loss: 0.4220 - lr: 0.0012\n",
      "Epoch 30/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0667\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012059280169196428.\n",
      "70/70 [==============================] - 10s 139ms/step - loss: 0.0667 - val_loss: 0.4122 - lr: 0.0012\n",
      "Epoch 31/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1073\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0012047221135580912.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.1073 - val_loss: 0.3797 - lr: 0.0012\n",
      "Epoch 32/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0716\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.001203517373185605.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.0716 - val_loss: 0.4663 - lr: 0.0012\n",
      "Epoch 33/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0608\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00120231391210109.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.0608 - val_loss: 0.4274 - lr: 0.0012\n",
      "Epoch 34/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0573\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00120111161400564.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.0573 - val_loss: 0.4440 - lr: 0.0012\n",
      "Epoch 35/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0695\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0011999104788992553.\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.0695 - val_loss: 0.4837 - lr: 0.0012\n",
      "Epoch 36/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1026\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.001198710623080842.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.1026 - val_loss: 0.3435 - lr: 0.0012\n",
      "Epoch 37/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.001197511930251494.\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.1511 - val_loss: 0.3824 - lr: 0.0012\n",
      "Epoch 38/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0956\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0011963144004112109.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.0956 - val_loss: 0.3819 - lr: 0.0012\n",
      "Epoch 39/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0522\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.001195118033559993.\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.0522 - val_loss: 0.3631 - lr: 0.0012\n",
      "Epoch 40/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0562\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0011939229459967465.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.0562 - val_loss: 0.4780 - lr: 0.0012\n",
      "Epoch 41/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0708\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.001192729021422565.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.0708 - val_loss: 0.4354 - lr: 0.0012\n",
      "Epoch 42/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0514\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0011915362598374486.\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.0514 - val_loss: 0.4495 - lr: 0.0012\n",
      "Epoch 43/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0626\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0011903447775403037.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "70/70 [==============================] - 10s 141ms/step - loss: 0.0626 - val_loss: 0.4146 - lr: 0.0012\n",
      "Epoch 43: early stopping\n",
      "2/2 [==============================] - 6s 25ms/step\n",
      "0.1497, 0.3121, 0.6680\n",
      "______fold 5______, ________repeat 2__________\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:48\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:959\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    962\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    963\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    964\u001b[0m           args, kwds))\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_5/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "blls = []\n",
    "\n",
    "units_1 = 32 \n",
    "drop_1 = 0.0 #0.75 # 0.0 my_\n",
    "dense_units = 8\n",
    "\n",
    "units_2 = 16\n",
    "drop_2 = 0.0 #0.5 # 0.0 my_\n",
    "\n",
    "units_3 = 8\n",
    "drop_3 = 0.0 #0.25 #0.0 my_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "\n",
    "#  cv was some kind of Multi-label. \n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(X, (tgt + 1) * (tgt2 - 3))):\n",
    "    for k in range(2):#10 # 2 my_\n",
    "        print(f'______fold {n+1}______, ________repeat {k+1}__________')\n",
    "\n",
    "        inputs_1 = tf.keras.Input(shape=(56,))\n",
    "        \n",
    "        features_1 = VariableSelectionFlow(56, units_1, drop_1, dense_units=dense_units)(inputs_1)\n",
    "        features_2 = VariableSelectionFlow(units_1, units_2, drop_2)(features_1)         \n",
    "        features_3 = VariableSelectionFlow(units_2, units_3, drop_3)(features_2)         \n",
    "\n",
    "        outputs = L.Dense(1, activation=\"sigmoid\")(features_3)\n",
    "\n",
    "        model = Model(inputs=inputs_1, outputs=outputs)      \n",
    "        # X[train_idx].shape => (555, 56)\n",
    "        \n",
    "        #print(model.summary(expand_nested=True))  \n",
    "        #model(X[train_idx][:12])\n",
    "        #tf.keras.utils.plot_model(model, to_file=\"model.png\", expand_nested=True, show_shapes=True)\n",
    "        \n",
    "        opt = O.Adam(.001234, epsilon=1e-7) # 1e-3\n",
    "        #opt = O.Adam(.00001234, epsilon=1e-7) # 1e-3\n",
    "        loss = binary_crossentropy\n",
    "\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_loss\", mode='min', factor=0.999, patience=1, verbose=1, min_lr=.0001234) # factor=0.95\n",
    "        #lr = ReduceLROnPlateau(monitor=\"val_loss\", mode='min', factor=0.999, patience=1, verbose=1, min_lr=.000001234) # factor=0.95\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', patience=25, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        model.compile(optimizer=opt, loss=loss)\n",
    "\n",
    "        #model.load_weights(f'best_weights/mod_f{n}.h5')\n",
    "        \n",
    "        history = model.fit(x=X[train_idx], # [:125] my_\n",
    "                          y=tgt[train_idx], # [:125] my_\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=250, #200 #300 my_\n",
    "                          validation_data=(X[val_idx], tgt[val_idx]),\n",
    "                          callbacks=[lr,es]\n",
    "                )                \n",
    "            \n",
    "        probs = model.predict(X[val_idx])[:,0]        \n",
    "        bll = balanced_log_loss_np(train_df.Class.values[val_idx], probs)\n",
    "        blls.append(bll)\n",
    "        val_loss = np.asarray(history.history['val_loss'])\n",
    "        train_loss = np.asarray(history.history['loss'])\n",
    "        min_val_loss = val_loss.min()\n",
    "        min_train_loss = train_loss[val_loss.argmin()]\n",
    "        print(f'{min_train_loss:.4f}, {min_val_loss:.4f}, {bll:.4f}')  \n",
    "        \n",
    "        model.save_weights(f'ICR_tf_adv_models/mod_f{n}_r{k}_tr{min_train_loss:.4f}_val{min_val_loss:.4f}.h5')\n",
    "\n",
    "print(np.mean(blls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3838a-79e2-494b-9593-26b60ce9f048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c243b-55c9-453b-aa72-84e24b650cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022da8c-a66e-440c-8162-6a0732f7d251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a8086-501a-4857-a71d-61f55cf941f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
